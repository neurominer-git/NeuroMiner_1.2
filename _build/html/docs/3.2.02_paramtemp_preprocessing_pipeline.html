
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Preprocessing pipeline &#8212; NeuroMiner Manual</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classification algorithm" href="3.2.03_paramtemp_classification_algorithm.html" />
    <link rel="prev" title="Cross-validation settings" href="3.2.01_paramtemp_cv_settings.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nm_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NeuroMiner Manual</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    <no title>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1.0_introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.1_prerequisites.html">
   Suggested Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.2_gettingstarted.html">
   Getting Started
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NeuroMiner interface
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="3.0_mainmenu.html">
   Main interface overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.1_mainmenu_input_data.html">
   Data entry in NeuroMiner
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="3.2_mainmenu_define_parameter_template.html">
   Define parameter template
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.00_paramtemp_data_fusion.html">
     Data Fusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.01_paramtemp_cv_settings.html">
     Cross-validation settings
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Preprocessing pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.03_paramtemp_classification_algorithm.html">
     Classification algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.04_paramtemp_learning_algorithm_parameters.html">
     Learning algorithm parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.05_paramtemp_ensemble_generation_strategies.html">
     Ensemble generation strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.06_paramtemp_visualization_options.html">
     Visualization options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.07_paramtemp_model_saving_options.html">
     Model saving options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.08_paramtemp_save_parameter_template.html">
     Save parameter template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.09_paramtemp_load_training_template.html">
     Load training template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.10_paramtemp_define_verbosity_level.html">
     Define verbosity level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.11_paramtemp_stacking.html">
     Stacking
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.3_mainmenu_initialize_delete_analyses.html">
   Initialize analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.4_mainmenu_preprocess_features.html">
   Preprocess features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.5_mainmenu_train_supervised_classifiers.html">
   Train supervised classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.6_mainmenu_visualize_classifiers.html">
   Visualize classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.7_mainmenu_display_training_results.html">
   Display training results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.8_mainmenu_generate_master_files.html">
   Generate master files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.9_mainmenu_OOCV_analysis.html">
   Out of Sample Cross-Validation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="4.0_Example.html">
   Example
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Functions in development
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="3.10_mainmenu_investigate_sample_size.html">
   Investigate sample size (simulation)
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fdocs/3.2.02_paramtemp_preprocessing_pipeline.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/3.2.02_paramtemp_preprocessing_pipeline.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#add-preprocessing-step">
   Add preprocessing step
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enable-spatial-operations-using-spatial-op-wizard">
   Enable spatial operations using Spatial OP Wizard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regress-out-nuisance-covariates">
   Regress out nuisance covariates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-dimensionality-reduction-method-to-data">
   Apply dimensionality reduction method to data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-subspaces">
     Extracting Subspaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardize-data">
   Standardize data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scale-data">
   Scale data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalize-to-group-mean">
   Normalize to group mean
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalize-to-unit-vector">
   Normalize to unit vector
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-binning-method-to-data">
   Apply binning method to data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#impute-missing-values">
   Impute missing values
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-imputation-method">
     1 | Define imputation method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-for-imputation">
     2: Select features for imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-number-of-nearest-neighbors">
     3 | Define number of nearest-neighbors
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prune-non-informative-columns-from-data-matrix">
   Prune non-informative columns from data matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remove-group-level-differences-using-offset-correction">
   Remove Group-level differences using offset correction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rank-weight-features">
   Rank / Weight features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extract-variance-components-from-data">
   Extract variance components from data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-deviation-from-normative-data">
   Measure deviation from normative data
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Preprocessing pipeline</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#add-preprocessing-step">
   Add preprocessing step
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enable-spatial-operations-using-spatial-op-wizard">
   Enable spatial operations using Spatial OP Wizard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regress-out-nuisance-covariates">
   Regress out nuisance covariates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-dimensionality-reduction-method-to-data">
   Apply dimensionality reduction method to data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-subspaces">
     Extracting Subspaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardize-data">
   Standardize data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scale-data">
   Scale data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalize-to-group-mean">
   Normalize to group mean
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalize-to-unit-vector">
   Normalize to unit vector
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-binning-method-to-data">
   Apply binning method to data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#impute-missing-values">
   Impute missing values
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-imputation-method">
     1 | Define imputation method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#select-features-for-imputation">
     2: Select features for imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-number-of-nearest-neighbors">
     3 | Define number of nearest-neighbors
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prune-non-informative-columns-from-data-matrix">
   Prune non-informative columns from data matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remove-group-level-differences-using-offset-correction">
   Remove Group-level differences using offset correction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rank-weight-features">
   Rank / Weight features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extract-variance-components-from-data">
   Extract variance components from data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-deviation-from-normative-data">
   Measure deviation from normative data
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="preprocessing-pipeline">
<span id="paramtemp-preprocessing-pipeline"></span><h1>Preprocessing pipeline<a class="headerlink" href="#preprocessing-pipeline" title="Permalink to this headline">#</a></h1>
<p>An important part of any machine learning analysis is how the data is prepared or ’preprocessed’ prior to its analysis with a classification algorithm. This is also known as ’feature extraction’ because the features are extracted from the existing data before analysis. NeuroMiner has a number of options to prepare data and can be tailored to a users specific data problem.</p>
<p>It’s important to note that NeuroMiner performs preprocessing steps within the cross-validation framework. This means that when the option to preprocess the data is selected, it preprocesses the training data and applies the ’learned’ preprocessing parameters to the CV1 and CV2 test data partitions.</p>
<p>When the preprocessing module is loaded the user will see the following:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-menu">
<img alt="neurominer preprocessing pipeline menu" src="../_images/NM_preproc_menu_imaging.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Importantly, the preprocessing steps that are selected will be outlined <strong>in order of processing</strong> under the heading <strong>CV-Preprocessing Sequence</strong>. The user can add steps using the add preprocessing step and can modify steps using the other straightforward options within this menu–e.g., the user can modify the settings of a preprocessing step or can change the order of the steps.</p>
</div>
<section id="add-preprocessing-step">
<span id="id1"></span><h2>Add preprocessing step<a class="headerlink" href="#add-preprocessing-step" title="Permalink to this headline">#</a></h2>
<p>This option is to add a preprocessing step to the ”Preprocessing sequence generator”. Once this is selected, the user can select the option that they would like from the following list:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-add">
<img alt="neurominer preprocessing options" src="../_images/NM_preproc_add.png" />
</figure>
<p>If you are using volumetric neuroimaging data, then there will also be an option included at the top of the list to: 1 : Enable spatial operations using Spatial OP Wizard. This is a special module designed to optimize filtering and smoothing within the cross-validation process and is always performed before any other preprocessing steps across the entire dataset (i.e., on test and training data). Once the user has selected one of the steps, for example to perform a dimensionality reduction, they are then redirected to the main preprocessing menu that will add the processing step; for example:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-pipe">
<img alt="neurominer preprocessing pipeline" src="../_images/NM_preproc_pipe.png" />
</figure>
<p>You can see that now there is a line stating CV-PREPROCESSING SEQUENCE containing ”Step 3: Dimensionality reduction”. The ”Preprocessing sequence generator” indicates that the step is selected for further operations as indicated 3/3 (one out of a total of three) steps and this selection is also highlighted by the arrow symbols (&gt;&gt;). If an option requires a suboption (e.g., <span class="xref myst">dimensionality reduction</span>) then the suboption will be listed underneath the parent option and this can be selected using the arrows as well.</p>
<p>As such, you can now perform other operations within this menu, including removing the selected preprocessing step, inserting another preprocessing step at the same location, replacing the current preprocessing step with another one, or modifying the current preprocessing step. If you have added a spatial preprocessing step, then this will appear above this menu because it is conducted prior to the preprocessing sequence across the entire dataset.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The preprocessing steps will be conducted in the order that they appear in the CV-PREPROCESSING SEQUENCE menu.</p>
</div>
</section>
<section id="enable-spatial-operations-using-spatial-op-wizard">
<span id="spatial-op"></span><h2>Enable spatial operations using Spatial OP Wizard<a class="headerlink" href="#enable-spatial-operations-using-spatial-op-wizard" title="Permalink to this headline">#</a></h2>
<p>If your active data modality is neuroimaging data, you should see the following option (see also {numref}(fig:3.2.02_nm_preproc_menu)):</p>
<p><strong>1 | Select spatial operation [ No filtering ]</strong></p>
<p>On turning on this mode, you will see the following menu:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-filter-options">
<img alt="neurominer preprocessing spatial smoothing" src="../_images/NM_preproc_smoothing.png" />
</figure>
<p>Once an option is selected and the parameters have been defined, you will see a new field above the ”CV-PREPROCESSING SEQUENCE”  as follows:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-pipe2">
<img alt="neurominer preprocessing pipeline2" src="../_images/NM_preproc_pipe2.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In NeuroMiner, it is designated as ”NON-CV PREPROCESSING” because it occurs across the entire dataset before preprocessing. However, as described below, it’s important to note that for smoothing the user can select a range of parameters and then the optimal combination of smoothing parameters, preprocessing settings, and training settings is found.</p>
</div>
<p><strong>2: Absolute difference filtering (6 neighbors)</strong></p>
<p>Absolute difference filtering is when the difference is computed between the voxel and each of the 6 nearest neighbors surrounding it. Then the value of the voxel is divided by the summed differences of the neighbors.</p>
<p><strong>3: Cube variance filtering (27 neighbors)</strong></p>
<p>The variance of the 27 neighbors surrounding each voxel is calculated and then the intensity of the target voxel is multiplied by the inverse of this variance.</p>
<p><strong>4: Gaussian smoothing (=<span class="math notranslate nohighlight">\(&gt;\)</span>FWHM)</strong></p>
<p>This is regular Gaussian smoothing as used in most neuroimaging toolboxes. The advantage of doing this in NeuroMiner is that you can specify multiple different smoothing kernels (e.g., [6 8 10]) and then these will be used as hyperparameters during optimization. That is, during learning in CV1 folds, the best combination of smoothing, other preprocessing steps, and learning parameters will be determined and applied to the held-out CV2 fold.</p>
<p><strong>5: Resampling (=<span class="math notranslate nohighlight">\(&gt;\)</span>Voxel size)</strong></p>
<p>This is regular voxel resampling as used in neuroimaging toolboxes. In similarity to smoothing, the advantage of having it in NeuroMiner is that you can optimize across different resampling parameters to find the best combination of resampling, preprocessing, and training.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>A critical point to remember in this mode is that if the user is interested in observing the Z-score by using <a class="reference internal" href="3.6_mainmenu_visualize_classifiers.html#mainmenu-visualize-classifiers"><span class="std std-ref"><strong>visualization</strong></span></a>, it is essential for the user to use smooth data first. Applying a scaling model to unsmoothed imaging data will likely result in extremely high/low values in the test data due to non-overlap of tissue borders between training and test cases.</p>
</div>
</section>
<section id="regress-out-nuisance-covariates">
<h2>Regress out nuisance covariates<a class="headerlink" href="#regress-out-nuisance-covariates" title="Permalink to this headline">#</a></h2>
<p>If covariates have been entered when the data was entered into NeuroMiner (see 4.1.8), then you can apply the correction using this step. This option is designed to remove the variance associated with a nuisance variable (e.g., age, sex, study center) from the data within each CV fold. When chosen it will reveal the following options:</p>
<p><strong>1 | Select method</strong></p>
<p>The first option gives you two possible methods to regress out the covariates: Partial Correlations and ComBat. Partial correlations method computes the coefficients that generate the chosen covariate effects in the data with a general linear model. In addition to the partial correlations method, ComBat method also scales the variance estimators. It allows to separate the label (eg. disease) effects and the covariate effects in the data to some degree. For more detailed information about the ComBat method please check <a class="reference external" href="https://academic.oup.com/biostatistics/article/8/1/118/252073">Johnson et al.,
2007</a>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please be aware that ComBat does not provide you with an external validation mode if new sites appear in the test data. For this case, there is a function in NeuroMiner called nk_MultiCentIntensNorm2.m. This function binarizes the interacting covariate and finds the bin with the largest overlap (N) between sites. In this subgroup it computes partial correlation coefficients or offsets and applies those to the entire group to correct for site effects.</p>
</div>
<p><strong>2 | Select covariates from NM covariates matrix</strong></p>
<p>Selecting the second option will allow you to choose the covariates that you want to control the data with. You select the covariate(s) by entering in either a single numeral (e.g., 1) or many (e.g., 1:2) relating to the covariates that have been previously entered. Once these are selected, the user will be returned to the partial correlations setup menu.</p>
<p><strong>3 | include intercept</strong></p>
<p>The choice of whether to include an intercept
is based on your research question and relate to intercept inclusion in
any other use of regression.</p>
<p><strong>4 | attenuate or increase covariate effects</strong></p>
<p>Allows the user to
either attenuate or increase the effects of the covariate on the data
using regression.</p>
<p><strong>5 | use externally-computed beta coefficients</strong></p>
<p>Allows the user to
enter beta coefficients from a regression that has been previously
calculated. This option only works if the dimensionality of the beta
coefficients exactly matches the dimensionality of the data. This means
that NM will crash if the dimensionality of the data is dynamically
changed during previous preprocessing steps.</p>
<p><strong>6 | Define subgroup of training cases for computing betas</strong></p>
<p>Option 5 allows the user to define a subgroup of training cases for computing beta coefficients, which are then applied to the data (as discussed in the supplementary material of <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25935725">Koutsouleris et al.,
2015</a> and <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0022193">Dukart et al.,
2016</a>). This function is useful when the user does not want to remove variance that may interact with the target of interest. For example, brain volume in schizophrenia interacts with age, therefore, the relationship between age and brain volume can be modeled in the control participants only and then these beta coefficients can be used in the schizophrenia sample to remove the effects of age without removing the effects of illness.</p>
<p>When this option is selected, you will see that another option <strong>7 | Provide index to training cases for computing betas</strong> is added to the menu. Select it to define a logical vector consisting of TRUE and FALSE corresponding to the participants in the study; e.g., [0 0 0 0 1 1 1 1]. A FALSE value (i.e., a zero) indicates that they will not be used in the calculation of the betas. A TRUE value (i.e., a 1) indicates that they will be used in the calculation of the betas. Logical vectors can be created from normal double vectors by simply typing ”logical(yourvector)” on the command line (“0”s and “1”s will automatically treated as logical values as well).</p>
</section>
<hr class="docutils" />
<section id="apply-dimensionality-reduction-method-to-data">
<h2>Apply dimensionality reduction method to data<a class="headerlink" href="#apply-dimensionality-reduction-method-to-data" title="Permalink to this headline">#</a></h2>
<p>A common need in machine learning analysis is to reduce the dimensionality of the data within the cross-validation framework (e.g., with structural neuroimages containing about 50,000 voxels). NeuroMiner allows the user to do this using a number of different methods.
When the option to reduce dimensionality is selected, the user will be shown the following menu:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-dimred">
<img alt="neurominer preprocessing dimred" src="../_images/NM_preproc_dimred.png" />
</figure>
<p>Each of these options will ask for parameters that are specific to the type of dimensionality reduction being conducted and are included in the respective sites for each technique listed below.</p>
<p>The main variable that can be changed across dimensionality reduction types is the number of dimensions that are retained following reduction (e.g., retaining 10 PCA components following dimensionality reduction of neuroimaging data). The following example applies to PCA reduction because this is the most common and we have found that it produces robust results.</p>
<p>For PCA, NeuroMiner gives the option to select the number of dimensions with the following options:</p>
<blockquote>
<div><p>1 | Define extraction mode for PCA [ Energy range ]
2 | Define extraction range [ 0.8 ]</p>
</div></blockquote>
<p>These options allow the user to select how the components are extracted and an extraction range based on this setting. When option 1 is selected, you will see the following menu:</p>
<blockquote>
<div><p>1 | Absolute number range [ 1 … n ] of eigenvectors
2 | Percentage range [ 0 … 1 ] of max dimensionality
3 | Energy range [ 0 … 1 ] of maximum decomposition</p>
</div></blockquote>
<p><strong>1 | Absolute number range [ 1 … n ] of eigenvectors</strong>:  A whole number of components that they would like to retain a priori.</p>
<p><strong>2 | Percentage range [ 0 … 1 ] of max dimensionality</strong>: A percentage of components to keep out of the total number of components.</p>
<p><strong>3 | Energy range [ 0 … 1 ] of maximum decomposition</strong>: Retaining components based on the percentage of the total amount of variance explained (i.e., energy). For example, you might want to keep all components that explain 80% of the variance of your data.</p>
<p>For each of these options, except PLS, NeuroMiner gives the user the option to optimize the number of components that are selected during cross-validation by specifying a range of values. For example, a range of 20%, 40%, and 60% can be selected by entering [0.2 0.4 0.6]. NeuroMiner will then conduct all optimization procedures using these percentages of retained variance–i.e., it will find the best PCA reduction considering the other settings. If a range of values is required, then it is recommended that an additional substep is performed.</p>
<section id="extracting-subspaces">
<h3>Extracting Subspaces<a class="headerlink" href="#extracting-subspaces" title="Permalink to this headline">#</a></h3>
<p>NeuroMiner has an additional option to first conduct the decomposition and then to retain different component numbers for further analysis. You do this by following the above procedure, but specifying that you want to retain a singular value of components (e.g., for PCA, 100% of the energy is recommended for the next step). Then you return to the preprocessing menu and select the option to ”Add a preprocessing step”. In the list of steps, there will now be an option to ”Extract subspaces from reduced data projections” and the following menu will appear:</p>
<blockquote>
<div><p>1 | Define extraction mode for PCA [ Energy range ]
2 | Define extraction range [ 1 ]</p>
</div></blockquote>
<p>Using these functions you can then select the components that you want to retain without having to run separate dimensionality reduction analyses. For example, you can retain 100% of the energy in the first step of a PCA to reduce the data dimensions and then retain a range of subspaces of components in the second step; e.g., [0.2 0.4 0.6 0.8]. This dramatically increases processing time.
The following advanced dimensionality reduction techniques are also offered by NeuroMiner, and the settings will change based on the technique. We recommend to follow the links provided below to determine the settings that are required or to evaluate the default settings offered within NeuroMiner.</p>
<div class="admonition-dimensionality-reduction-techniques admonition">
<p class="admonition-title">Dimensionality Reduction Techniques</p>
<ol class="simple">
<li><p>Principal Component Analysis (PCA) - <a class="reference external" href="http://www.cad.zju.edu.cn/home/dengcai/Data/DimensionReduction.html">PCA by Deng
Cai</a></p></li>
<li><p>Robust Principal Component Analysis -
<a class="reference external" href="http://wis.kuleuven.be/stat/robust/LIBRA/LIBRA-home">LIBRA</a><br />
Note that RPCA is significantly slower than PCA but more accurate in
low N problems.</p></li>
<li><p>Non-negative Matrix Factorization - <a class="reference external" href="https://sites.google.com/site/nmftool/">Li and Ngom’s NMF
toolbox</a><br />
Note that NMF is significantly slower than PCA but more parsimonious
&amp; robust.</p></li>
<li><p>Partial Least Squares performs a single value decomposition (SVD; matlab built-in) on a covariance matrix constructed from the entered features plus another feature set to get latent variables. For example, if the primary features are voxels from a brain and the secondary PLS feature set are the labels it conducts SVD on the combined matrix (after standardization). It then multiplies this unitary matrix (U) from the SVD with the original standardized primary feature matrix in order to sensitize the analysis to the combination of the features. Other data can be used in place of the labels. The user has the option to use sparse PLS based on the function ”spls”.</p></li>
<li><p>Sparse PCA - [Please check preproc/spca.m; <a class="reference external" href="http://www.it.dtu.dk/projects/manifold/Papers/sparsepc.pdf">Zou et al.,
2004</a>]
This is a ‘statistical segmentation’ tool.</p></li>
<li><p>Simple Principal Component Analysis - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Probabilistic PCA - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
This is for low dimensional problems only, it requires</p></li>
</ol>
<blockquote>
<div><p>32GB RAM for high-D data.</p>
</div></blockquote>
<ol class="simple">
<li><p>Factor analysis - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Locality Preserving Projections – <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
This is for low-dimensional problems only. Number of cases needs to
be &gt; no. features.</p></li>
<li><p>Linear Local Tangent Space Alignment - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
For low-D only, requires &gt;32 GB RAM for high-D
data.</p></li>
<li><p>Large-Margin Nearest Neighbour - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Deep Autoencoder – <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
Low dimensional data only.</p></li>
<li><p>Neighborhood Component Analysis <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
Low dimensional data only.</p></li>
</ol>
<p><em>For all techniques see nk_PerfRedObj.m</em>
<em>For implementation of all functions, please see nk_PerfRedObj.m and files in the preproc directory.</em></p>
</div>
</section>
</section>
<hr class="docutils" />
<section id="standardize-data">
<h2>Standardize data<a class="headerlink" href="#standardize-data" title="Permalink to this headline">#</a></h2>
<p>The standardization, scaling, and/or normalization of data is an important part of most machine learning. NeuroMiner contains different methods to perform these functions within the preprocessing modules, which are conducted within each inner cross-validation fold. Standardization is conducted on each of the features that have been entered to NeuroMiner across observations.</p>
<p>When option “3” is selected, the user will see the following:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-standard">
<img alt="neurominer preprocessing standardization menu" src="../_images/NM_preproc_standard.png" />
</figure>
<p><strong>1 | Select standardization method</strong></p>
<p>Select from the following standardization options:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-standard-method">
<img alt="neurominer preprocessing standardization methods" src="../_images/NM_preproc_standard_method.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="simple">
<li><p>calculates the Z-score using the median (i.e., (score -median) / standard deviation).</p></li>
<li><p>calculates the Z-score using the mean.</p></li>
<li><p>mean-centers all features (i.e., subtraction of the mean for the feature across all scores).</p></li>
<li><p>L1-median centering calculates the multivariate L1-median and then takes the derivatives from this as features (see nk PerfStandardizeObj.m; Hossjer and Crous (1995) Generalizing univariate signed rank statistics for testing and estimating a multivariate location parameter, Non-parametric statistics, 4, 293-308).</p></li>
<li><p>and 6. are alternatives to the median absolute deviation for standardizing multivariate data (see <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476408?journalCode=uasa20">Rousseeuw and Croux (1993)</a>.</p></li>
</ol>
</div>
<p><strong>2 | Compute standardization using a subgroup of cases [no]</strong></p>
<p>User can compute the standardization using a subgroup of cases.</p>
<p><strong>3 | Apply standardization model to a subgroup of cases [no]</strong></p>
<p>User can apply the standardization model to a subgroup of cases.</p>
<p><strong>4 | Winsorize data (clamping of outliers) [no]</strong></p>
<p>The user also has the option to Winsorize or ’censor’ the data. This technique was introduced to account for outliers. After standardization, the elements which are outside of a user-defined range (e.g., 4 standard deviations) are set to their closest percentile. For example, data above the 95th percentile is set to the value of the 95th percentile. The feature is then re-centered using the new censored values.</p>
<p><strong>5 | Zero-out completely non-finite features [yes]</strong></p>
<p>If there are entries in the user’s feature data that are non-numeric (i.e., ”NaN” or ”not a number” elements), then these will not be considered during the calculation of the mean and standard deviation (NeuroMiner uses the nanmean function). However, after the data has been standardized, these values will be added back to the feature matrix. As such, NeuroMiner gives the option to change these to zero in step four. It is important to note that once the data has been standardized, zero values reflect the mean of the feature and are thus a form of mean imputation. If the user wants to use other imputation options, they can select ’no’ to this option and then impute the data using the preprocessing imputation option.</p>
</section>
<hr class="docutils" />
<section id="scale-data">
<h2>Scale data<a class="headerlink" href="#scale-data" title="Permalink to this headline">#</a></h2>
<p>Another option to put the data into the same space is to scale it between two values. The user will see the following menu when they select this option:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-scale">
<img alt="neurominer preprocessing scale menu" src="../_images/NM_preproc_scale.png" />
</figure>
<p><strong>1 | Scale across features or each feature independently [each feature independently]</strong></p>
<p>Here you have the choice between scaling  ”each feature independently” or ”across the entire matrix”. If each feature independently is selected, then the data will be scaled within the desired range for each feature (i.e., each voxel or each questionnaire). If the entire matrix is selected then each value in the matrix will be scaled according to the range of all the data (e.g., all voxels or all questionnaires).</p>
<p><strong>2 | Define scale range [0,1]</strong></p>
<p>The user then has the option to define the scale range between 0 and 1 or between -1 to 1. These two chices are provided because some machine learning algorithms require the data to be scaled differently; e.g., the liblinear options require the data to be scaled between -1 to 1.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure to check whether the algorithm of your choice requires a certain scale!</p>
</div>
<p><strong>3 | Zero-out completely non-finite features [yes]</strong></p>
<p>Non-numeric values are not taken into account during scaling and are added back to the matrix after scaling. The third option gives the user the ability to either change these values to zero following scaling by selecting ”yes” for the third option to ”zero-out completely non-finite features”. It is critical to note that in this case the values will be considered to be the absolute minimum of the scale for future analyses (e.g., if IQ is scaled, then these individuals will have an IQ value of 0). For questionnaire data, it is recommended that this option is changed to ”no”, and instead imputation is performed after scaling for the NaN elements. Alternatively, for imaging data, it is recommended that NaN values are excluded by using a brainmask during data input.</p>
</section>
<hr class="docutils" />
<section id="normalize-to-group-mean">
<h2>Normalize to group mean<a class="headerlink" href="#normalize-to-group-mean" title="Permalink to this headline">#</a></h2>
<p>This option is only available when a group has been entered as a covariate at the start of the analysis (i.e., dummy coded vector containing ones for the group and zeros for the other participants). The option will then normalize all subjects to the mean of the specified group.</p>
</section>
<hr class="docutils" />
<section id="normalize-to-unit-vector">
<h2>Normalize to unit vector<a class="headerlink" href="#normalize-to-unit-vector" title="Permalink to this headline">#</a></h2>
<p>This option takes the mean of the data, then subtracts this from each of the scores within the data. It then calculates the norm (L1 or L2) of this result. It then mean-centers the original data and divides each score by the normalized scores.</p>
</section>
<hr class="docutils" />
<section id="apply-binning-method-to-data">
<h2>Apply binning method to data<a class="headerlink" href="#apply-binning-method-to-data" title="Permalink to this headline">#</a></h2>
<p>Binning is a technique that can be used to control for variance in data (<a class="reference external" href="https://en.wikipedia.org/wiki/Data_binning">wiki</a>). For example, a histogram is an example of data binning. A form of it is discretization of continuous features (<a class="reference external" href="https://en.wikipedia.org/wiki/Discretization_of_continuous_features">wiki</a>) and this is offered in NeuroMiner as the default option when binning is selected as follows:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-binning">
<img alt="neurominer preprocessing binning menu" src="../_images/NM_preproc_binning.png" />
</figure>
<p>Discretization basically just forms bins based on the standard deviation. You first establish a vector using a start value, a stepping value, and a stop value called alpha (e.g., the default setting is [0 0.5 1 1.5 2 2.5 3 3.5 4]). It then discretizes each feature by the mean +/- alpha*std. For example, for the first value of alpha, it finds the feature values that are above and below the mean and gives them a new value (i.e., 1 or -1). Then in the next step it finds the values that are above and below the mean +/- half of the standard deviation and gives them a new value (i.e., 2 or -2). In the next step it finds values that are above and below one standard deviation from the mean and gives them a new value (i.e., 3 or -3). And so on. In this way, bins are created with a width that is determined by the standard deviation. It is important to note that this function will perform Winsorization (i.e., clamping) because values the stop value of alpha (e.g., above 4 standard deviations above or below the mean) will be given the final value.</p>
<p>Manually determining the bins is a good way to discretize data if you have a firm idea about the problem, but if you do not then it is useful to find an optimal bin width for a feature by taking into account the information content of the data. This can be done in NeuroMiner by changing the ”1: Select binning method” to ”Unsupervised entropy-based symbolization”. It tries to find an optimal bin width for a feature by taking into account the entropy. It will do this within the range that you specify in the following settings:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-binning-method">
<img alt="neurominer preprocessing binning methods" src="../_images/NM_preproc_binning_method.png" />
</figure>
</section>
<hr class="docutils" />
<section id="impute-missing-values">
<h2>Impute missing values<a class="headerlink" href="#impute-missing-values" title="Permalink to this headline">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>NeuroMiner will only show this preprocessing option in the list in case there are NaN values in your data!</p>
</div>
<p>The machine learning algorithms included in NeuroMiner are not able to process missing values (represented in MATLAB as ”Not a Number” (NaN) entries). This means that they have to be either removed using the ”Prune non-informative columns” feature described below, or they need to be imputed using this module.
NeuroMiner performs imputation using either single-subject median replacement, feature-wise mean replacement, or multivariate distance-based nearest neighbor median imputation. When this feature is selected it will reveal the following menu:</p>
<blockquote>
<div><p>1 | Define imputation method [ kNN imputation (EUCLIDEAN) ]<br />
2 | Select features for imputation [ All features ]<br />
3 | Define number of nearest neighbors [ 7 nearest neighbors ]</p>
</div></blockquote>
<section id="define-imputation-method">
<h3>1 | Define imputation method<a class="headerlink" href="#define-imputation-method" title="Permalink to this headline">#</a></h3>
<p>You have to first define the imputation method using the following menu:</p>
<blockquote>
<div><p>1 | Median of non-NaN values in given case<br />
2 | Mean of non-NaN values in given feature<br />
3 | MANHATTAN distance-based nearest-neighbor search<br />
4 | EUCLIDEAN distance-based nearest-neighbor search<br />
5 | SEUCLIDEAN distance-based nearest-neighbor search<br />
6 | COSINE similarity-based nearest-neighbor search<br />
7 | HAMMING distance-based nearest-neighbor search<br />
8 | JACCARD distance-based nearest-neighbor search<br />
9 | Nearest-neighbor imputation using hybrid method</p>
</div></blockquote>
<p>For median or mean replacement, values are imputed based on the data
either across features for one subject or across subjects within the
feature. For multivariate nearest-neighbor imputation, for each case
with NaN values, a multivariate statistical technique is conducted to
identify a number of similar (i.e., nearest-neighbor) cases from all the
subjects that are available. For example, the Euclidean distance could
be used to identify the 7 nearest-neighbor subjects that are close to
the subject with the NaN value. Once these similar cases are identified
in the multivariate space, then NeuroMiner will take the median of their values of the feature with the missing NaN case and impute it into the
NaN field. A number of distance metrics can be used to represent the
cases in multivariate space and to determine the nearest-neighbors based
on the type of data you have (e.g., Manhattan, Euclidean, Seuclidean,
Cosine, Hamming, or Jaccard). For example, the Euclidean distance could
be used for data with a continuous measurement scale or the Hamming
could be used for binary nominal data (i.e., 0 or 1) data (see Box:
Nominal Data). There is also the option to use a hybrid approach that
accounts for both continuous/ordinal and nominal data. It’s important to
note that all options except for the Manhattan and Euclidean distances
require the Statistics and Machine Learning Toolbox of MATLAB.</p>
<p><strong>1 | Median of non-NaN values in given case</strong></p>
<p>This function checks NaN values for each subject. When it finds a NaN
value for a subject, it imputes the median of the non-NaN values across
the other features for that subject. Therefore, this would make no sense
at all if it was done across features that weren’t equivalent in scale
or from the same scale (e.g., a questionnaire). As such, it could be
used in combination with the option to “2 | Select features for
imputation” described below.</p>
<p><strong>2 | Mean of non-NaN values in given feature</strong></p>
<p>This function cycles through each feature and if it finds a NaN value
then it imputes the mean of non-NaN values.</p>
<p><strong>3 | MANHATTAN distance-based nearest-neighbor search</strong></p>
<p>This function determines the Manhattan distance between cases and then
selects nearest-neighbors. It uses the ‘distance’ function from the
Large Margins Nearest-Neighbors (LMNN) toolbox version 2.5 <a class="reference external" href="http://www.cs.cornell.edu/~kilian/code/lmnn/lmnn.html">(link)</a>. You
must scale, unit-normalize or standardize the data first, otherwise the distance measure will be dominated by high-variance features.</p>
<p><strong>4 | EUCLIDEAN distance-based nearest-neighbor search</strong></p>
<p>Determines the Euclidean distance between cases and then selects
nearest-neighbors. It uses the ‘distance2’ function from the Large
Margins Nearest-Neighbors (LMNN) toolbox version 2.5
<a class="reference external" href="http://www.cs.cornell.edu/~kilian/code/lmnn/lmnn.html">(link)</a>. You
must scale, unit-normalize or standardize the data first, otherwise the
distance measure will be dominated by high-variance features.</p>
<p><strong>5 | SEUCLIDEAN distance-based nearest-neighbor search</strong></p>
<p>The Seuclidean distance between cases is measured using the pdist2
function that is built into the Statistics and Machine Learning Toolbox
of MATLAB.</p>
<p><strong>6 | COSINE similarity-based nearest-neighbor search</strong></p>
<p>The Cosine distance between cases is measured using the pdist2 function
that is built into the Statistics and Machine Learning Toolbox of
MATLAB.</p>
<p><strong>7 | HAMMING distance-based nearest-neighbor search</strong></p>
<p>The Hamming distance between cases can be used for nominal data (e.g.,
0/1 data) and is measured using the pdist2 function that is built into
the Statistics and Machine Learning Toolbox of MATLAB.</p>
<p><strong>8 | JACCARD distance-based nearest-neighbor search</strong></p>
<p>The Jaccard distance between cases is measured using the pdist2 function
that is built into the Statistics and Machine Learning Toolbox of
MATLAB.</p>
<p><strong>9 | Nearest-neighbor imputation using hybrid method</strong></p>
<p>This option combines techniques that can be used for binary nominal data
(i.e., 0/1) and ordinal/continuous data. You must define a method for
nominal features (e.g., Hamming or Jaccard) and then define a method for
ordinal/continuous features (e.g., Euclidean or Cosine). The maximum
number of unique values for nominal feature imputation must also be
inputted.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Nominal Data. It is important to remember that nominal data with more than two categories needs to be dummy-coded for the results to make sense (i.e., 0 or 1 coding). NeuroMiner does not recognise the data-types and therefore nominal data that is coded with more than three categories (e.g., 1=De pression; 2=Bipolar; 3=Schizophrenia) will be used as a variable with meaningful relationships between the numbers when differences are actually arbitrary.</p>
</div>
</section>
<section id="select-features-for-imputation">
<h3>2: Select features for imputation<a class="headerlink" href="#select-features-for-imputation" title="Permalink to this headline">#</a></h3>
<p>The imputation procedures can be applied to the entire dataset or to
subsets of the data. This is useful when there are different data
domains (e.g., clinical and cognitive data) or even single
questionnaires (e.g., the PANSS) that you want to restrict the
imputation to. A MATLAB logical vector (i.e., consisting of TRUE and
FALSE fields that are depicted as [0 0 0 1 1 0 0 etc.]; you can
convert a binary vector to a logical simply by typing
logical(yourvector) on the command line) must be provided to select a
subset. If you want to impute multiple subsets then you must add
separate imputation routines.</p>
</section>
<section id="define-number-of-nearest-neighbors">
<h3>3 | Define number of nearest-neighbors<a class="headerlink" href="#define-number-of-nearest-neighbors" title="Permalink to this headline">#</a></h3>
<p>If you’re using the multivariate nearest-neighbors approach then you
must define the number of nearest neighbors (e.g., subjects) to use for
the calculation of the median value. The default is 7.</p>
</section>
</section>
<hr class="docutils" />
<section id="prune-non-informative-columns-from-data-matrix">
<h2>Prune non-informative columns from data matrix<a class="headerlink" href="#prune-non-informative-columns-from-data-matrix" title="Permalink to this headline">#</a></h2>
<p>Data pruning is the removal of examples or features that will not work with machine learning algorithms or are redundant. In NeuroMiner, the machine learning algorithms that are used cannot work with missing values (i.e., ”Not a Number” (NaN) entries in MATLAB) or with infinite values (i.e., ”Inf” in MATLAB), which can occur due to previous processing steps. If the values of a feature do not change between participants (i.e., there is zero variance), then it is redundant to include the feature in the analysis as well. To correct for these problems, NeuroMiner offers the following options:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-prune">
<img alt="neurominer preprocessing pruning" src="../_images/NM_preproc_prune.png" />
</figure>
<p><strong>1 | Prune zero features [ no ]</strong></p>
<blockquote>
<div><p>The first option gives the user the ability to remove variables with no variance within a fold (i.e., if all individuals, or ’examples’ within a cross-validation fold have exactly the same value for a feature).</p>
</div></blockquote>
<p><strong>2 | Prune features with NaNs [ yes ]</strong></p>
<blockquote>
<div><p>The second option will remove features within a fold that have any NaN (’Not a Number’) values.</p>
</div></blockquote>
<p><strong>3 | Prune features with Infs [ yes ]</strong></p>
<blockquote>
<div><p>Similarly, the third option will allow users to remove features with any Infs (Infinity) values.</p>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Be careful with pruning It is important to note that even if there is one subject with one NaN or Inf within the fold NeuroMiner will remove the feature. The amount of removed features will be difficult to quantify. For matrix data, check the NaNs and potentially filter then prior to the entry into NeuroMiner (see <a class="reference internal" href="3.1_mainmenu_input_data.html#fig-3-1-nm-feature-selector"><span class="std std-numref">Fig. 5</span></a>).</p>
</div>
<p><strong>4 | Prune features with single-value percentage over cutoff [ yes, 5 ]</strong></p>
<blockquote>
<div><p>The fourth option is used in situations where there are a large number of subjects with the same value and a few with different values. For example, in neuroimaging due to registration inaccuracies most of the subjects may have a voxel value of zero in a location close to the gray matter border and a few might have non-zero numbers. In these circumstances, you might want to exclude the voxels where there is no variance in, for example, 90% of the sample (e.g., where 90% of individuals have a zero value). You can specify a percentage here to do this.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="remove-group-level-differences-using-offset-correction">
<h2>Remove Group-level differences using offset correction<a class="headerlink" href="#remove-group-level-differences-using-offset-correction" title="Permalink to this headline">#</a></h2>
<p>This function was introduced primarily to control for scanner differences in structural neuroimaging data. In the case of two centers, for each feature, the mean of both center A and center B is calculated. The mean difference between these is then calculated (A-B=Y) and then subtracted from each of the data points in A (i.e., Ai - Y). This value is stored for further analysis. Internal empirical tests indicate that this basic method can control for major site differences.</p>
</section>
<hr class="docutils" />
<section id="rank-weight-features">
<h2>Rank / Weight features<a class="headerlink" href="#rank-weight-features" title="Permalink to this headline">#</a></h2>
<p>Selecting or ranking features is an important part of machine learning and can be achieved with filters and wrappers. For a discussion of why these methods are important and for all definitions see <a class="reference external" href="http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf">Guyon et
al., 2003</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Wrappers and filters will further be discussed in <span class="xref myst">ensemble generation straqtegies</span>.</p>
</div>
<p>Filter methods broadly involve the weighting and ranking of variables, and optionally the selection of top performing variables. This can be conducted either prior to the evaluation of the model during pre-processing or as part of model optimisation (discussed in section <span class="xref myst">ensemble generation straqtegies</span>). This option allows the user to weight variables in the training folds based on some criteria (e.g., Pearson’s correlation coefficient with the target variable) and then rank them in a specified order (e.g., descending order from most to least correlated). When this option is selected, the following will be displayed:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-rank">
<img alt="neurominer preprocessing ranking" src="../_images/NM_preproc_rank.png" />
</figure>
<p><strong>1 | Choose algorithm and specify its parameters</strong></p>
<p>The user here has the option to choose from among a number of methods
that will weight the relationship between the filter target and the
feature. These are:</p>
<figure class="align-default" id="fig-3-2-02-nm-preproc-rank-method">
<img alt="neurominer preprocessing pruning" src="../_images/NM_preproc_rank_method.png" />
</figure>
<ol class="simple">
<li><p><strong>Pearson / Spearman correlation</strong>:
Standard MATLAB functions for Pearson’s (corrcoef).</p></li>
<li><p><strong>Spearman correlation</strong>:
Standard MATLAB function for Spearman’s (corr).</p></li>
<li><p>G-flip (Greedy Feature Flip):
See <a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/Papers/giladbachrachnavottishby04b.pdf">Gilad-Bachrach et al.
(2004)</a>
and
<a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/code/feature_selection.bak/">site</a></p></li>
<li><p>Simba:
See <a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/Papers/giladbachrachnavottishby04b.pdf">Gilad-Bachrach et al.
(2004)</a>
and
<a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/code/feature_selection.bak/">link</a></p></li>
<li><p>IMRelief:
This is an implementation of the Yijun Sun IMRelief function called
“IMRelief Sigmoid FastImplentation” (see <a class="reference external" href="http://plaza.ufl.edu/sunyijun/Paper/ICML06_1.pdf">Sun &amp; Li,
2007</a>).</p></li>
<li><p>Relief for classification:
This is a version of the built-in MATLAB ReliefF algorithm
<a class="reference external" href="https://de.mathworks.com/help/stats/relieff.html">(link</a>).</p></li>
<li><p>Linear SVC (LIBSVM):
This weights the features by conducting a linear SVM using each
independent feature, as implemented in LIBSVM <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">(Chang &amp;
Lin</a>).</p></li>
<li><p>Linear SVC (LIBLINEAR):
Weights the features based on using LIBLINEAR toolbox
(<a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">link</a>)</p></li>
<li><p>F-Score:
Weights the features based on conducting an ANOVA using standard MATLAB
functions on the differences between the groups when problem is
classification.</p></li>
<li><p>AUC:
Calculates an area under the curve (AUC) for binary classifications
based on the code of Chih-Jen Lin and then ranks the features based on
this.</p></li>
<li><p>FEAST:
Implementation of the FEAST toolbox for feature selection
(<a class="reference external" href="http://www.cs.man.ac.uk/~gbrown/fstoolbox/">site</a>).</p></li>
<li><p>ANOVA:
Standard implementation of ANOVA.</p></li>
<li><p>PLS:
Performs a Partial Least Squares analysis to rank the features.</p></li>
<li><p>External ranking:
This option uses a user-defined weighting template that was entered
during [data input] (mainmenu_3.1_input_data), to use an external weighting map
from a file, or to read-in a weighting vector using the MATLAB
workspace.</p></li>
</ol>
<p><strong>2 | Define target labels</strong>
Here the user defines the target label that the filter will be applied to using the original data; e.g., this could be your group labels if you have a classification problem or your questionnaire item if you’re using regression. The default setting in NeuroMiner is to use your target variable, but this can be changed by first selecting the menu item and then entering ”D” to define a new target label. A new menu will appear and you can select to enter either categorical or continuous data. You can then enter a MATLAB vector that defines either categorical labels (e.g., [0 0 0 0 1 1 1 1]) or continuous labels (e.g., [15 26 19 33 22]). These variables should be stored in your MATLAB workspace. When a continuous variable is selected, the user will then be asked whether they want to weight feature using only one specific subgroup. This means that the feature will only be weighted only based on the relationship between the feature and the filter target in one subgroup (e.g., control participants).</p>
<p><strong>3 | Up- or down-weight predictive features</strong>
This option allows the user to either upweight or downweight the features based on the relationship between the variable and the target. For example, if you want to increase the importance of the features based on the target you would upweight the features. If you want to reduce the importance of the fea tures based on some other variable (e.g., age if it is a nuisance variable) you could select the variable as the feature selection target and then choose the downweight option. For more information about why you would want to do this see references above.</p>
</section>
<hr class="docutils" />
<section id="extract-variance-components-from-data">
<h2>Extract variance components from data<a class="headerlink" href="#extract-variance-components-from-data" title="Permalink to this headline">#</a></h2>
<p>This function takes a source matrix and performs a PCA. It then determines correlations between the eigenvariates from the PCA reduction, and those above or below a specified threshold are identified. It then projects the target matrix to the source matrix PCA space, and then back-reconstructs this to the original input space without the identified PCA components (i.e., it removes the variance associated with those components).</p>
</section>
<hr class="docutils" />
<section id="measure-deviation-from-normative-data">
<h2>Measure deviation from normative data<a class="headerlink" href="#measure-deviation-from-normative-data" title="Permalink to this headline">#</a></h2>
<p>This function calculates a PLS and then determines how much the data deviates from the model that is produced. The hypothesis here is that the PLS model will represent a normative variation between the primary features (e.g., the brain) and the second feature matrix (e.g., the labels or another variable set). By calculating the deviation from this model, it is hypothesized that normative deviation will be modeled and then included in further processing steps.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="3.2.01_paramtemp_cv_settings.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Cross-validation settings</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="3.2.03_paramtemp_classification_algorithm.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classification algorithm</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Neurodiagnostics Lab LMU Munich<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>