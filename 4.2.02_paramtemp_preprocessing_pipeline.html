

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Preprocessing pipeline &#8212; NeuroMiner Manual</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-1F3TPH8HH8"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-1F3TPH8HH8');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '4.2.02_paramtemp_preprocessing_pipeline';</script>
    <link rel="canonical" href="https://neurominer-git.github.io/NeuroMiner_1.2/4.2.02_paramtemp_preprocessing_pipeline.html" />
    <link rel="shortcut icon" href="_static/nm_logo2.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Classification algorithm" href="4.2.03_paramtemp_classification_algorithm.html" />
    <link rel="prev" title="Cross-validation settings" href="4.2.01_paramtemp_cv_settings.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/nm_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/nm_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    NeuroMiner
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">News</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5.00_1.2_release_notes.html">NeuroMiner 1.2 (09/2023)</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2024_MLSchool.html">Online Machine Learning School 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2023_MLSchool.html">Online Machine Learning School 2023 - Europe</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2023_MLSchool_AsiaPacific.html">Online Machine Learning School 2023 - Asia-Pacific</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.0_previous_MLSchool.html">Past Schools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="1.0_introduction.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="license.html">License</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="2.0_prerequisites.html">Suggested Prerequisites</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="3.0_gettingstarted.html">Installation &amp; Configuration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3.0.00_macos_users.html">Setting up NeuroMiner on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="3.0.01_python_matlab.html">How to configure Python with Matlab for NeuroMiner on the server</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NeuroMiner interface</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4.0_mainmenu.html">Main interface overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.1_mainmenu_input_data.html">Data entry in NeuroMiner</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="4.2_mainmenu_define_parameter_template.html">Define parameter template</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="4.2.00_paramtemp_data_fusion.html">Data Fusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.01_paramtemp_cv_settings.html">Cross-validation settings</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Preprocessing pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.03_paramtemp_classification_algorithm.html">Classification algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.04_paramtemp_learning_algorithm_parameters.html">Learning algorithm parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.05_paramtemp_ensemble_generation_strategies.html">Ensemble generation strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.06_paramtemp_visualization_options.html">Visualization options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.07_paramtemp_interpretation_options.html">Prediction interpretation options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.08_paramtemp_model_saving_options.html">Model saving options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.09_paramtemp_define_verbosity_level.html">Define verbosity level</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.10_paramtemp_inspect_workspace.html">Inspect workspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.11_paramtemp_save_parameter_template.html">Save parameter template</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.12_paramtemp_load_training_template.html">Load training template</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.13_paramtemp_multigroup.html">Multi-group analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.14_paramtemp_stacking.html">Stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.15_paramtemp_different_label.html">Use different label</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.16_paramtemp_synthetic_data.html">Synthetic data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4.3_mainmenu_initialize_delete_analyses.html">Initialize analyses</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.4_mainmenu_preprocess_features.html">Preprocess features</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.5_mainmenu_train_supervised_classifiers.html">Train supervised classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.6_mainmenu_visualize_classifiers.html">Visualize classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.14_mainmenu_interprete_classifiers.html">Interprete predictions</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="4.7_mainmenu_display_training_results.html">Result Viewer</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4.7.01_mainmenu_display_visualization_results.html">Visualization results</a></li>

<li class="toctree-l2"><a class="reference internal" href="4.7.02_mainmenu_display_interpretation_results.html">ML Interpreter (MLI) results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4.8_mainmenu_OOCV_analysis.html">Out of Sample Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.15_mainmenu_export_model.html">Export model parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.9_mainmenu_load_struct.html">Load NeuroMiner structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.10_mainmenu_save_struct.html">Save NeuroMiner structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.11_mainmenu_change_wd.html">Change working directory</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.12_mainmenu_estimate_sample_size.html">Estimate sample size (simulation tool)</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.13_mainmenu_utilities.html">Utilities</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Parallelization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5.01_NM_compilation.html">Parallelization on HPC server - NeuroMiner compilation</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/neurominer-git/NeuroMiner_1.2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/neurominer-git/NeuroMiner_1.2/issues/new?title=Issue%20on%20page%20%2F4.2.02_paramtemp_preprocessing_pipeline.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/4.2.02_paramtemp_preprocessing_pipeline.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Preprocessing pipeline</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#add-preprocessing-step">Add preprocessing step</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enable-spatial-operations-using-spatial-op-wizard">Enable spatial operations using Spatial OP Wizard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regress-out-nuisance-covariates">Regress out nuisance covariates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-correlations-options">Partial Correlations options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combat-options">ComBat options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#disparate-impact-remover-options">Disparate Impact Remover options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-dimensionality-reduction-method-to-data">Apply dimensionality reduction method to data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-subspaces">Extracting Subspaces</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-data">Standardize data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scale-data">Scale data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalize-to-group-mean">Normalize to group mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalize-to-unit-vector">Normalize to unit vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-binning-method-to-data">Apply binning method to data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#impute-missing-values">Impute missing values</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-imputation-method">1 | Define imputation method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-for-imputation">2 | Select features for imputation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-number-of-nearest-neighbors">3 | Define number of nearest-neighbors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prune-non-informative-columns-from-data-matrix">Prune non-informative columns from data matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remove-group-level-differences-using-offset-correction">Remove group-level differences using offset correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-weight-features">Rank / Weight features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extract-variance-components-from-data">Extract variance components from data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measure-deviation-from-normative-data">Measure deviation from normative data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-mode-target-scaling-transformation">Regression mode: Target scaling &amp; transformation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiclass-mode-one-vs-one-one-vs-all-modus">Multiclass mode: One vs. One, One vs. All Modus</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="preprocessing-pipeline">
<span id="id1"></span><h1>Preprocessing pipeline<a class="headerlink" href="#preprocessing-pipeline" title="Permalink to this heading">#</a></h1>
<p>An important part of any machine learning analysis is how the data is prepared or ’preprocessed’ prior to its analysis with a classification algorithm. This is also known as ’feature extraction’ because the features are extracted from the existing data before analysis. NeuroMiner has a number of options to prepare data and can be tailored to a user’s specific data problem.</p>
<p>It’s important to note that NeuroMiner performs preprocessing steps within the cross-validation framework. This means that when the option to preprocess the data is selected, it preprocesses the training data and applies the ’learned’ preprocessing parameters to the CV1 and CV2 test data partitions.</p>
<p>When the preprocessing module is loaded the user will see the following:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-menu">
<img alt="neurominer preprocessing pipeline menu" src="_images/NM_preproc_menu.png" />
<p class="caption"><span class="caption-number">Fig. 10 </span><span class="caption-text">NeuroMiner preprocessing pipeline setup</span><a class="headerlink" href="#fig-3-2-02-nm-preproc-menu" title="Permalink to this image">#</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Importantly, the preprocessing steps that are selected will be outlined <strong>in order of processing</strong> under the heading <strong>CV-Preprocessing Sequence</strong>. The user can add steps using the add preprocessing step and can modify steps using the other straightforward options within this menu–e.g., the user can modify the settings of a preprocessing step or can change the order of the steps.</p>
</div>
<div class="section" id="add-preprocessing-step">
<span id="preprocessing-pipeline-add"></span><h2>Add preprocessing step<a class="headerlink" href="#add-preprocessing-step" title="Permalink to this heading">#</a></h2>
<p>This option is to add a preprocessing step to the ”Preprocessing sequence generator”. Once this is selected, the user can select the option that they would like from the following list:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-add">
<img alt="neurominer preprocessing options" src="_images/NM_preproc_add.png" />
</div>
<p>If you are using volumetric neuroimaging data, then there will also be an option included at the top of the list to: <strong>1 | Enable spatial operations using Spatial OP Wizard</strong>. This is a special module designed to optimize filtering and smoothing within the cross-validation process and is always performed before any other preprocessing steps across the entire dataset (i.e., on test and training data). Once the user has selected one of the steps, for example to perform a dimensionality reduction, they are redirected to the main preprocessing menu that will add the processing step; for example:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-pipe">
<img alt="neurominer preprocessing pipeline" src="_images/NM_preproc_pipe.png" />
</div>
<p>You can see that now there is a line stating CV-PREPROCESSING SEQUENCE containing ”Step 3: Dimensionality reduction”. The ”Preprocessing sequence generator” indicates that the step is selected for further operations as indicated 3/3 (one out of a total of three) steps and this selection is also highlighted by the arrow symbols (&gt;&gt;). If an option requires a suboption (e.g., <a class="reference internal" href="#preproc-dim-red"><span class="std std-ref">dimensionality reduction</span></a>) then the suboption will be listed underneath the parent option and this can be selected using the arrows as well.</p>
<p>As such, you can now perform other operations within this menu, including removing the selected preprocessing step, inserting another preprocessing step at the same location, replacing the current preprocessing step with another one, or modifying the current preprocessing step. If you have added a spatial preprocessing step, then this will appear above this menu because it is conducted prior to the preprocessing sequence across the entire dataset.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The preprocessing steps will be conducted in the order that they appear in the CV-PREPROCESSING SEQUENCE menu.</p>
</div>
</div>
<div class="section" id="enable-spatial-operations-using-spatial-op-wizard">
<span id="spatial-op"></span><h2>Enable spatial operations using Spatial OP Wizard<a class="headerlink" href="#enable-spatial-operations-using-spatial-op-wizard" title="Permalink to this heading">#</a></h2>
<p>If your active data modality is neuroimaging data, you should see the following option (see also <a class="reference internal" href="#fig-3-2-02-nm-preproc-menu"><span class="std std-numref">Fig. 10</span></a>):</p>
<p><strong>1 | Select spatial operation [ No filtering ]</strong></p>
<p>After enabling this mode, you will see the following menu:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-filter-options">
<img alt="neurominer preprocessing spatial smoothing" src="_images/NM_preproc_smoothing.png" />
</div>
<p>Once an option is selected and the parameters have been defined, you will see a new field above the ”CV-PREPROCESSING SEQUENCE”  as follows:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-pipe2">
<img alt="neurominer preprocessing pipeline2" src="_images/NM_preproc_pipe2.png" />
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In NeuroMiner, it is designated as ”NON-CV PREPROCESSING” because it occurs across the entire dataset before preprocessing. However, as described below, it’s important to note that for smoothing the user can select a range of parameters and then the optimal combination of smoothing parameters, preprocessing settings, and training settings is found.</p>
</div>
<p><strong>2 | Absolute difference filtering (6 neighbors)</strong></p>
<p>Absolute difference filtering is when the difference is computed between the voxel and each of the 6 nearest neighbors surrounding it. Then the value of the voxel is divided by the summed differences of the neighbors.</p>
<p><strong>3 | Cube variance filtering (27 neighbors)</strong></p>
<p>The variance of the 27 neighbors surrounding each voxel is calculated and then the intensity of the target voxel is multiplied by the inverse of this variance.</p>
<p><strong>4 | Gaussian smoothing (=<span class="math notranslate nohighlight">\(&gt;\)</span>FWHM)</strong></p>
<p>This is regular Gaussian smoothing as used in most neuroimaging toolboxes. The advantage of doing this in NeuroMiner is that you can specify multiple different smoothing kernels (e.g., [6 8 10]) and then these will be used as hyperparameters during optimization. That is, during learning in CV1 folds, the best combination of smoothing, other preprocessing steps, and learning parameters will be determined and applied to the held-out CV2 fold.</p>
</div>
<hr class="docutils" />
<div class="section" id="regress-out-nuisance-covariates">
<h2>Regress out nuisance covariates<a class="headerlink" href="#regress-out-nuisance-covariates" title="Permalink to this heading">#</a></h2>
<p>If covariates have been entered alongside the <a class="reference internal" href="4.1_mainmenu_input_data.html#input-data"><span class="std std-ref">data</span></a>, you can apply covariate correction using this step. This option is designed to remove the variance associated with a nuisance variable (e.g., age, sex, study center) from the data within each CV fold. When chosen it will reveal the following options:</p>
<div class="figure align-default" id="fig-nm-preproc-residualization">
<img alt="neurominer residualization Options" src="_images/NM_preproc_residualization.png" />
</div>
<p><strong>1 | Select method</strong></p>
<p>The first option gives you three possible methods to regress out the covariates: Partial Correlations, ComBat and Disparate Impact Remover (DIR). The partial correlations method computes the coefficients that generate the chosen covariate effects in the data with a general linear model. In addition to the partial correlations method, ComBat also scales the variance estimators. It allows to separate the label (e.g., disease) effects and the covariate effects in the data to some degree. For more detailed information about the ComBat method please check <a class="reference external" href="https://academic.oup.com/biostatistics/article/8/1/118/252073">Johnson et al.,
2007</a>. Currently, Combat can only be used to correct for batch effects (e.g. site, sex). It requires a numeric vector encoding batch effects to be modeled out. In contrast, partial correlations should be used with a dummy-coded matrix if the user wants to correct for batch effects using this method. Finally, DIR is a method that allows users to transform the features of the dataset so that predictions are fair and do not disproportionately disadvantage any particular group (e.g., race, gender or age groups). Briefly, the algorithm calculates the distribution of values for each selected feature for two or more subject groups (e.g., males and females), calculates the median/mean distribution for all subjects, and applies a percentage of correction (known as repair level, or alpha) to each group towards that median/mean distribution. For a more detailed explanation of the DIR method, please visit the original publication <a class="reference external" href="https://doi.org/10.48550/arXiv.1412.3756">Feldman et al., 2014</a>.</p>
<p>Depending on the selected method, the following configuration options will change. Below there is a description of the options for each method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please be aware that ComBat does not provide you with an external validation mode if new sites appear in the test data. For this case, there is a function in NeuroMiner called nk_MultiCentIntensNorm2.m. This function binarizes the interacting covariate and finds the bin with the largest overlap (N) between sites. In this subgroup it computes partial correlation coefficients or offsets and applies those to the entire group to correct for group effects.</p>
</div>
</div>
<div class="section" id="partial-correlations-options">
<h2>Partial Correlations options<a class="headerlink" href="#partial-correlations-options" title="Permalink to this heading">#</a></h2>
<p><strong>2 | Select covariates from NM covariate matrix</strong></p>
<p>Selecting the second option will allow you to choose the covariates that you want to control the data with. You select the covariate(s) by entering in either a single numeral (e.g., 1) or many (e.g., 1:2) relating to the covariates that have been previously entered. Once these are selected, the user will be returned to the partial correlations setup menu. Currently, the DIR method only allows for categorical covariates.</p>
<p><strong>3 | Use intercept in partial correlation analysis</strong></p>
<p>The choice of whether to include an intercept is based on your research question and relate to intercept inclusion in any other use of regression.</p>
<p><strong>4 | Attenuate or increase covariate effects</strong></p>
<p>Allows the user to either attenuate or increase the effects of the covariate on the data using regression.</p>
<p><strong>5 | use externally-computed beta coefficients</strong></p>
<p>Allows the user to
enter beta coefficients from a regression that has been previously
calculated. This option only works if the dimensionality of the beta
coefficients exactly matches the dimensionality of the data. This means
that NM will crash if the dimensionality of the data is dynamically
changed during previous preprocessing steps.</p>
<p><strong>6 | Define subgroup of training cases for computing betas</strong></p>
<p>Option 5 allows the user to define a subgroup of training cases for computing beta coefficients, which are then applied to the data (as discussed in the supplementary material of <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25935725">Koutsouleris et al.,
2015</a> and <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0022193">Dukart et al.,
2016</a>). This function is useful when the user does not want to remove variance that may interact with the target of interest. For example, brain volume in schizophrenia interacts with age, therefore, the relationship between age and brain volume can be modeled in the control participants only and then these beta coefficients can be used in the schizophrenia sample to remove the effects of age without removing the effects of illness.</p>
<p>When this option is selected, you will see that another option <strong>7 | Provide index to training cases for computing betas</strong> is added to the menu. Select it to define a logical vector consisting of TRUE and FALSE corresponding to the participants in the study; e.g., [0 0 0 0 1 1 1 1]. A FALSE value (i.e., a zero) indicates that they will not be used in the calculation of the betas. A TRUE value (i.e., a 1) indicates that they will be used in the calculation of the betas. Logical vectors can be created from normal double vectors by simply typing ”logical(yourvector)” on the command line (“0”s and “1”s will automatically treated as logical values as well).</p>
</div>
<div class="section" id="combat-options">
<h2>ComBat options<a class="headerlink" href="#combat-options" title="Permalink to this heading">#</a></h2>
<p><strong>2 | Select covariates from NM covariate matrix</strong></p>
<p>Selecting the second option will allow you to choose the covariates that you want to control the data with. You select the covariate(s) by entering in either a single numeral (e.g., 1) or many (e.g., 1:2) relating to the covariates that have been previously entered. Once these are selected, the user will be returned to the partial correlations setup menu. Currently, the DIR method only allows for categorical covariates.</p>
<p><strong>3 | Retain variance effects during correction</strong></p>
<p>This option allows to retain the variance effects from a selected covariate of interest, while correcting from batch effects from the covariate selected in the option 2. If this option is set to “yes”, a new option will appear: <strong>4 | Define retainment covariates (ComBat method)</strong> which allows the user to select the retainment covariate in a analogous fashion to the removed covariate in option 2. Additionally, another option will also be added: <strong>5 | Include NM label in variance retainment</strong>. This option allows to include the label (e.g., control vs. schizophrenia) as a retainment covariate. This means that the ComBat algorithm will retain the variance from the different label groups.</p>
<p><strong>6 | Define subgroup of training cases</strong></p>
<p>Option 5 allows the user to define a subgroup of training cases for the ComBat correction, which are then applied to the data (as discussed in the supplementary material of <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25935725">Koutsouleris et al.,
2015</a> and <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0022193">Dukart et al.,
2016</a>). This function is useful when the user does not want to remove variance that may interact with the target of interest. For example, brain volume in schizophrenia interacts with age, therefore, the relationship between age and brain volume can be modeled in the control participants only and then the same ComBat correction can be used in the schizophrenia sample to remove the effects of age without removing the effects of illness.</p>
<p>When this option is selected, you will see that another option <strong>7 | Provide index to training cases</strong> is added to the menu. Select it to define a logical vector consisting of TRUE and FALSE corresponding to the participants in the study; e.g., [0 0 0 0 1 1 1 1]. A FALSE value (i.e., a zero) indicates that they will not be used in the ComBat calculation. A TRUE value (i.e., a 1) indicates that they will be used in the calculation. Logical vectors can be created from normal double vectors by simply typing ”logical(yourvector)” on the command line (“0”s and “1”s will automatically treated as logical values as well).</p>
</div>
<div class="section" id="disparate-impact-remover-options">
<h2>Disparate Impact Remover options<a class="headerlink" href="#disparate-impact-remover-options" title="Permalink to this heading">#</a></h2>
<p><strong>2 | Select covariates from NM covariate matrix</strong></p>
<p>Selecting the second option will allow you to choose the covariates that you want to control the data with. You select the covariate(s) by entering in either a single numeral (e.g., 1) or many (e.g., 1:2) relating to the covariates that have been previously entered. Once these are selected, the user will be returned to the partial correlations setup menu. Currently, the DIR method only allows for categorical covariates.</p>
<p><strong>3 | Type of distribution</strong></p>
<p>Measure used to calculate the “ideal” feature distribution used for correction. If the mean is selected, then the ideal distribution is calculated by calculating the mean of frequency of each bin among all the distributions from the covariate groups. If the median is selected, the same process is applied, but using the median.</p>
<p><strong>4 | Strength of correction</strong></p>
<p>This option determines the repair level. A value of 0 will apply no correction (the feature distribution will remain the same), while a strength of correction of 1 will totally correct the distributions to the mean/median distribution among the covariate groups.</p>
<p><strong>5 | Define subgroup of training cases</strong></p>
<p>Option 5 allows the user to define a subgroup of training cases for computing the DIR distributions, which are then applied to the data (as discussed in the supplementary material of <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/25935725">Koutsouleris et al.,
2015</a> and <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0022193">Dukart et al.,
2016</a>). This function is useful when the user does not want to remove variance that may interact with the target of interest.</p>
<p>When this option is selected, you will see that another option <strong>6 | Provide index to training cases</strong> is added to the menu. Select it to define a logical vector consisting of TRUE and FALSE corresponding to the participants in the study; e.g., [0 0 0 0 1 1 1 1]. A FALSE value (i.e., a zero) indicates that they will not be used in the calculation of the distributions. A TRUE value (i.e., a 1) indicates that they will be used in the calculation. Logical vectors can be created from normal double vectors by simply typing ”logical(yourvector)” on the command line (“0”s and “1”s will automatically treated as logical values as well).</p>
<hr class="docutils" />
</div>
<div class="section" id="apply-dimensionality-reduction-method-to-data">
<span id="preproc-dim-red"></span><h2>Apply dimensionality reduction method to data<a class="headerlink" href="#apply-dimensionality-reduction-method-to-data" title="Permalink to this heading">#</a></h2>
<p>A common need in machine learning analysis is to reduce the dimensionality of the data within the cross-validation framework (e.g., with structural neuroimages containing about 50,000 voxels). NeuroMiner allows the user to do this using a number of different methods.
When the option to reduce dimensionality is selected, the user will be shown the following menu:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-dimred">
<img alt="neurominer preprocessing dimred" src="_images/NM_preproc_dimred.png" />
</div>
<p>Each of these options will ask for parameters that are specific to the type of dimensionality reduction being conducted and are included in the respective sites for each technique listed below.</p>
<p>The main variable that can be changed across dimensionality reduction types is the number of dimensions that are retained following reduction (e.g., retaining 10 PCA components following dimensionality reduction of neuroimaging data). The following example applies to PCA reduction because this is the most common and we have found that it produces robust results.</p>
<p>For PCA, NeuroMiner gives the option to select the number of dimensions with the following options:</p>
<blockquote>
<div><p>1 | Define extraction mode for PCA [ Energy range ]
2 | Define extraction range [ 0.8 ]</p>
</div></blockquote>
<p>These options allow the user to select how the components are extracted and an extraction range based on this setting. When option 1 is selected, you will see the following menu:</p>
<blockquote>
<div><p>1 | Absolute number range [ 1 … n ] of eigenvectors
2 | Percentage range [ 0 … 1 ] of max dimensionality
3 | Energy range [ 0 … 1 ] of maximum decomposition</p>
</div></blockquote>
<p><strong>1 | Absolute number range [ 1 … n ] of eigenvectors</strong>:  A whole number of components that they would like to retain a priori.</p>
<p><strong>2 | Percentage range [ 0 … 1 ] of max dimensionality</strong>: A percentage of components to keep out of the total number of components.</p>
<p><strong>3 | Energy range [ 0 … 1 ] of maximum decomposition</strong>: Retaining components based on the percentage of the total amount of variance explained (i.e., energy). For example, you might want to keep all components that explain 80% of the variance of your data.</p>
<p>For each of these options, except PLS, NeuroMiner gives the user the option to optimize the number of components that are selected during cross-validation by specifying a range of values. For example, a range of 20%, 40%, and 60% can be selected by entering [0.2 0.4 0.6]. NeuroMiner will then conduct all optimization procedures using these percentages of retained variance–i.e., it will find the best PCA reduction considering the other settings. If a range of values is required, then it is recommended that an additional substep is performed.</p>
<div class="section" id="extracting-subspaces">
<h3>Extracting Subspaces<a class="headerlink" href="#extracting-subspaces" title="Permalink to this heading">#</a></h3>
<p>NeuroMiner has an additional option to first conduct the decomposition and then to retain different component numbers for further analysis. You do this by following the above procedure, but specifying that you want to retain a singular value of components (e.g., for PCA, 100% of the energy is recommended for the next step). Then you return to the preprocessing menu and select the option to ”Add a preprocessing step”. In the list of steps, there will now be an option to ”Extract subspaces from reduced data projections” and the following menu will appear:</p>
<blockquote>
<div><p>1 | Define extraction mode for PCA [ Energy range ]
2 | Define extraction range [ 1 ]</p>
</div></blockquote>
<p>Using these functions you can then select the components that you want to retain without having to run separate dimensionality reduction analyses. For example, you can retain 100% of the energy in the first step of a PCA to reduce the data dimensions and then retain a range of subspaces of components in the second step; e.g., [0.2 0.4 0.6 0.8]. This drastically increases processing time.
The following advanced dimensionality reduction techniques are also offered by NeuroMiner, and the settings will change based on the technique. We recommend to follow the links provided below to determine the settings that are required or to evaluate the default settings offered within NeuroMiner.</p>
<div class="admonition-dimensionality-reduction-techniques admonition">
<p class="admonition-title">Dimensionality Reduction Techniques</p>
<ol class="arabic simple">
<li><p>Principal Component Analysis (PCA) - <a class="reference external" href="http://www.cad.zju.edu.cn/home/dengcai/Data/DimensionReduction.html">PCA by Deng
Cai</a></p></li>
<li><p>Robust Principal Component Analysis -
<a class="reference external" href="http://wis.kuleuven.be/stat/robust/LIBRA/LIBRA-home">LIBRA</a><br />
Note that RPCA is significantly slower than PCA but more accurate in
low N problems.</p></li>
<li><p>Non-negative Matrix Factorization - <a class="reference external" href="https://sites.google.com/site/nmftool/">Li and Ngom’s NMF
toolbox</a><br />
Note that NMF is significantly slower than PCA but more parsimonious
&amp; robust.</p></li>
<li><p>Partial Least Squares performs a single value decomposition (SVD; matlab built-in) on a covariance matrix constructed from the entered features plus another feature set to get latent variables. For example, if the primary features are voxels from a brain and the secondary PLS feature set are the labels it conducts SVD on the combined matrix (after standardization). It then multiplies this unitary matrix (U) from the SVD with the original standardized primary feature matrix in order to sensitize the analysis to the combination of the features. Other data can be used in place of the labels. The user has the option to use sparse PLS based on the function ”spls”.</p></li>
<li><p>Sparse PCA - [Please check preproc/spca.m; <a class="reference external" href="http://www.it.dtu.dk/projects/manifold/Papers/sparsepc.pdf">Zou et al.,
2004</a>]
This is a ‘statistical segmentation’ tool.</p></li>
<li><p>Simple Principal Component Analysis - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Probabilistic PCA - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
This option is only for low dimensional problems, it requires
more than 32GB RAM for high-D data.</p></li>
<li><p>Factor analysis - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Locality Preserving Projections - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
This option is only for low-dimensional problems. Number of cases needs to be greater than the number of features.</p></li>
<li><p>Linear Local Tangent Space Alignment - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
For low-D only, requires &gt;32 GB RAM for high-D
data.</p></li>
<li><p>Large-Margin Nearest Neighbour - <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a></p></li>
<li><p>Deep Autoencoder – <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
Low dimensional data only.</p></li>
<li><p>Neighborhood Component Analysis <a class="reference external" href="https://lvdmaaten.github.io/drtoolbox/">MTDR; van der
Maaten</a>
This option is only for low-dimensional problems.</p></li>
<li><p>fastICA - <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html">fastICA, sklearn function</a>, <a class="reference external" href="https://www.cs.helsinki.fi/u/ahyvarin/papers/fastica.shtml">fastICA, publications, A. Hyvärinen</a></p></li>
<li><p>Orthogonal Projective Non-Negative Matrix Factorization - <a class="reference external" href="https://github.com/asotiras/brainparts">GitHub</a>, <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4357179/">Paper</a></p></li>
</ol>
<p><em>For an overview and the implementation of all techniques see nk_PerfRedObj.m and files in the preproc directory.</em></p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="standardize-data">
<h2>Standardize data<a class="headerlink" href="#standardize-data" title="Permalink to this heading">#</a></h2>
<p>The standardization, scaling, and/or normalization of data is an important part of most machine learning. NeuroMiner contains different methods to perform these functions within the preprocessing modules, which are conducted within each inner cross-validation fold. Standardization is conducted on each of the features that have been entered to NeuroMiner across observations.</p>
<p>When option “3” is selected, the user will see the following:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-standard">
<img alt="neurominer preprocessing standardization menu" src="_images/NM_preproc_standard.png" />
</div>
<p><strong>1 | Select standardization method</strong></p>
<p>Select from the following standardization options:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-standard-method">
<img alt="neurominer preprocessing standardization methods" src="_images/NM_preproc_standard_method.png" />
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>calculates the Z-score using the median (i.e., (score -median) / standard deviation / interquartile range).</p></li>
<li><p>calculates the Z-score using the mean.</p></li>
<li><p>mean-centers all features (i.e., subtraction of the mean for the feature across all scores).</p></li>
<li><p>calculates the multivariate L1-median and then takes the derivatives from this as features (see nk_PerfStandardizeObj.m; <a class="reference external" href="https://doi.org/10.1080/10485259508832620">Hossjer and Crous (1995)</a>.</p></li>
<li><p>and 6. are alternatives to the median absolute deviation for standardizing multivariate data (see <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476408?journalCode=uasa20">Rousseeuw and Croux (1993)</a>).</p></li>
</ol>
</div>
<p><strong>2 | Compute standardization using a subgroup of cases</strong></p>
<p>User can compute the standardization using a subgroup of cases.</p>
<p><strong>3 | Apply standardization model to a subgroup of cases</strong></p>
<p>User can apply the standardization model to a subgroup of cases.</p>
<p><strong>4 | Winsorize data (clamping of outliers)</strong></p>
<p>The user also has the option to Winsorize or ’censor’ the data. This technique was introduced to account for outliers. After standardization, the elements which are outside of a user-defined range (e.g., 4 standard deviations) are set to their closest percentile. For example, data above the 95th percentile is set to the value of the 95th percentile. The feature is then re-centered using the new censored values.</p>
<p><strong>5 | Zero-out completely non-finite features</strong></p>
<p>If there are entries in the user’s feature data that are non-numeric (i.e., ”NaN” or ”not a number” elements), then these will not be considered during the calculation of the mean and standard deviation (NeuroMiner uses the nanmean function). However, after the data has been standardized, these values will be added back to the feature matrix. As such, NeuroMiner gives the option to change these to zero in step four. It is important to note that once the data has been standardized, zero values reflect the mean of the feature and are thus a form of mean imputation. If the user wants to use other imputation options, they can select ’no’ to this option and then impute the data using the preprocessing imputation option.</p>
</div>
<hr class="docutils" />
<div class="section" id="scale-data">
<h2>Scale data<a class="headerlink" href="#scale-data" title="Permalink to this heading">#</a></h2>
<p>Another option to put the data into the same space is to scale it between two values. The user will see the following menu when they select this option:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-scale">
<img alt="neurominer preprocessing scale menu" src="_images/NM_preproc_scale.png" />
</div>
<p><strong>1 | Scale across features or each feature independently [each feature independently]</strong></p>
<p>Here you have the choice between scaling  ”each feature independently” or ”across the entire matrix”. If each feature independently is selected, then the data will be scaled within the desired range for each feature (i.e., each voxel or each questionnaire). If the entire matrix is selected then each value in the matrix will be scaled according to the range of all the data (e.g., all voxels or all questionnaires).</p>
<p><strong>2 | Define scale range [0,1]</strong></p>
<p>The user then has the option to define the scale range between 0 and 1 or between -1 to 1. These two chices are provided because some machine learning algorithms require the data to be scaled differently; e.g., the <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">LIBLINEAR</a> options require the data to be scaled between -1 to 1.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure to check whether the algorithm of your choice requires a certain scale!</p>
</div>
<p><strong>3 | Zero-out completely non-finite features [yes]</strong></p>
<p>Non-numeric values are not taken into account during scaling and are added back to the matrix after scaling. The third option gives the user the ability to either change these values to zero following scaling by selecting ”yes” for the third option to ”zero-out completely non-finite features”. It is critical to note that in this case the values will be considered to be the absolute minimum of the scale for future analyses (e.g., if IQ is scaled, then these individuals will have an IQ value of 0).</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For questionnaire data, it is recommended that this option is changed to ”no”, and instead imputation is performed for the NaN elements after scaling. Alternatively, for imaging data, it is recommended that NaN values are excluded by using a brainmask during data input. Furthermore, starting with NM 1.1, zero-variance columns encountered by the scaling function will be automatically set to zero instead of NaN. This allows for their subsequent removal using the pruning module, prior to e.g. imputation.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="normalize-to-group-mean">
<h2>Normalize to group mean<a class="headerlink" href="#normalize-to-group-mean" title="Permalink to this heading">#</a></h2>
<p>This option is only available when a group has been entered as a covariate at the start of the analysis (i.e., dummy coded vector containing ones for the group and zeros for the other participants). The option will then normalize all subjects to the mean of the specified group.</p>
</div>
<hr class="docutils" />
<div class="section" id="normalize-to-unit-vector">
<h2>Normalize to unit vector<a class="headerlink" href="#normalize-to-unit-vector" title="Permalink to this heading">#</a></h2>
<p>This option takes the mean of the data, then subtracts this from each of the scores within the data. It then calculates the norm (L1 or L2) of this result. It then mean-centers the original data and divides each score by the normalized scores.</p>
</div>
<hr class="docutils" />
<div class="section" id="apply-binning-method-to-data">
<h2>Apply binning method to data<a class="headerlink" href="#apply-binning-method-to-data" title="Permalink to this heading">#</a></h2>
<p>Binning is a technique that can be used to control for variance in data (<a class="reference external" href="https://en.wikipedia.org/wiki/Data_binning">wiki</a>). For example, a histogram is an example of data binning. A form of it is discretization of continuous features (<a class="reference external" href="https://en.wikipedia.org/wiki/Discretization_of_continuous_features">wiki</a>) and this is offered in NeuroMiner as the default option when binning is selected as follows:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-binning">
<img alt="neurominer preprocessing binning menu" src="_images/NM_preproc_binning.png" />
</div>
<p>Discretization basically just forms bins based on the standard deviation. You first establish a vector using a start value, a stepping value, and a stop value called alpha (e.g., the default setting is [0 0.5 1 1.5 2 2.5 3 3.5 4]). It then discretizes each feature by the mean +/- alpha*std. For example, for the first value of alpha, it finds the feature values that are above and below the mean and gives them a new value (i.e., 1 or -1). Then in the next step it finds the values that are above and below the mean +/- half of the standard deviation and gives them a new value (i.e., 2 or -2). In the next step it finds values that are above and below one standard deviation from the mean and gives them a new value (i.e., 3 or -3). And so on. In this way, bins are created with a width that is determined by the standard deviation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is important to note that this function will perform Winsorization (i.e., clamping) because values above the stop value of alpha (e.g., above 4 standard deviations above or below the mean) will be clamped to the user-defined alpha value (e.g. 4) .</p>
</div>
<p>Manually determining the bins is a good way to discretize data if you have a firm idea about the problem, but if you do not then it is useful to find an optimal bin width for a feature by taking into account the information content of the data. This can be done in NeuroMiner by changing the ”1: Select binning method” to ”Unsupervised entropy-based symbolization”. It tries to find an optimal bin width for a feature by taking into account the entropy. It will do this within the range that you specify in the following settings:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-binning-method">
<img alt="neurominer preprocessing binning methods" src="_images/NM_preproc_binning_method.png" />
</div>
</div>
<hr class="docutils" />
<div class="section" id="impute-missing-values">
<h2>Impute missing values<a class="headerlink" href="#impute-missing-values" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>NeuroMiner will only show this preprocessing option in the list in case there are NaN values in your data!</p>
</div>
<p>The machine learning algorithms included in NeuroMiner are not able to process missing values (represented in MATLAB as ”Not a Number” (NaN) entries). This means that they have to be either removed using the ”Prune non-informative columns” feature described below, or they need to be imputed using this module.
NeuroMiner performs imputation using either single-subject median replacement, feature-wise mean replacement, or multivariate distance-based nearest neighbor median imputation. When this feature is selected it will reveal the following menu:</p>
<blockquote>
<div><p>1 | Define imputation method [ kNN imputation (EUCLIDEAN) ]<br />
2 | Select features for imputation [ All features ]<br />
3 | Define number of nearest neighbors [ 7 nearest neighbors ]</p>
</div></blockquote>
<div class="section" id="define-imputation-method">
<h3>1 | Define imputation method<a class="headerlink" href="#define-imputation-method" title="Permalink to this heading">#</a></h3>
<p>You have to first define the imputation method using the following menu:</p>
<blockquote>
<div><p>1 | Median of non-NaN values in given case</p>
<p>2 | Mean of non-NaN values in given feature</p>
<p>3 | MANHATTAN distance-based nearest-neighbor search</p>
<p>4 | EUCLIDEAN distance-based nearest-neighbor search</p>
<p>5 | Sequential kNN-based imputation method (EUCLIDEAN)</p>
<p>6 | SEUCLIDEAN distance-based nearest-neighbor search</p>
<p>7 | COSINE similarity-based nearest-neighbor search</p>
<p>8 | HAMMING distance-based nearest-neighbor search</p>
<p>9 | JACCARD distance-based nearest-neighbor search</p>
<p>10 | Nearest-neighbor imputation using hybrid method</p>
</div></blockquote>
<p>For median or mean replacement, values are imputed based on the data
either across features for one subject or across subjects within the
feature. For multivariate nearest-neighbor imputation, for each case
with NaN values, a multivariate statistical technique is conducted to
identify a number of similar (i.e., nearest-neighbor) cases from all the
subjects that are available. For example, the Euclidean distance could
be used to identify the 7 nearest-neighbor subjects that are close to
the subject with the NaN value. Once these similar cases are identified
in the multivariate space, then NeuroMiner will take the median of their values of the feature with the missing NaN case and impute it into the
NaN field. A number of distance metrics can be used to represent the
cases in multivariate space and to determine the nearest-neighbors based
on the type of data you have (e.g., Manhattan, Euclidean, Seuclidean,
Cosine, Hamming, or Jaccard). For example, the Euclidean distance could
be used for data with a continuous measurement scale or the Hamming
could be used for binary nominal data (i.e., 0 or 1) data (see <a class="reference internal" href="#note-nominal-data"><span class="std std-ref"> Nominal Data</span></a>). There is also the option to use a hybrid approach that
accounts for both continuous/ordinal and nominal data. It’s important to
note that all options require the Statistics and Machine Learning Toolbox of MATLAB.</p>
<p><strong>Median of non-NaN values in given case</strong></p>
<p>This function checks NaN values for each subject. When it finds a NaN
value for a subject, it imputes the median of the non-NaN values across
the other features for that subject. Therefore, this would make no sense
at all if it was done across features that weren’t equivalent in scale
or from the same scale (e.g., a questionnaire). As such, it could be
used in combination with the option to “2 | Select features for
imputation” described below.</p>
<p><strong>Mean of non-NaN values in given feature</strong></p>
<p>This function cycles through each feature and if it finds a NaN value then it imputes the mean of non-NaN values.</p>
<p><strong>MANHATTAN distance-based nearest-neighbor search</strong></p>
<p>This function determines the Manhattan distance between cases and then selects nearest-neighbors. You must scale, unit-normalize or standardize the data first, otherwise the distance measure will be dominated by high-variance features.</p>
<p><strong>EUCLIDEAN distance-based nearest-neighbor search</strong></p>
<p>Determines the Euclidean distance between cases and then selects nearest-neighbors. You must scale, unit-normalize or standardize the data first, otherwise the distance measure will be dominated by high-variance features.</p>
<p><strong>Sequential kNN-based imputation method (EUCLIDEAN)</strong></p>
<p>Faster than previous option.</p>
<p><strong>SEUCLIDEAN distance-based nearest-neighbor search</strong></p>
<p>The Seuclidean distance between cases is measured using the pdist2
function that is built into the Statistics and Machine Learning Toolbox
of MATLAB.</p>
<p><strong>COSINE similarity-based nearest-neighbor search</strong></p>
<p>The Cosine distance between cases is measured using the pdist2 function
that is built into the Statistics and Machine Learning Toolbox of
MATLAB.</p>
<p><strong>HAMMING distance-based nearest-neighbor search</strong></p>
<p>The Hamming distance between cases can be used for nominal data (e.g.,
0/1 data) and is measured using the pdist2 function that is built into
the Statistics and Machine Learning Toolbox of MATLAB.</p>
<p><strong>JACCARD distance-based nearest-neighbor search</strong></p>
<p>The Jaccard distance between cases is measured using the pdist2 function
that is built into the Statistics and Machine Learning Toolbox of
MATLAB.</p>
<p><strong>Nearest-neighbor imputation using hybrid method</strong></p>
<p>This option combines techniques that can be used for binary nominal data
(i.e., 0/1) and ordinal/continuous data. You must define a method for
nominal features (e.g., Hamming or Jaccard) and then define a method for
ordinal/continuous features (e.g., Euclidean or Cosine). The maximum
number of unique values for nominal feature imputation must also be
specified.</p>
<div class="admonition-nominal-data admonition" id="note-nominal-data">
<p class="admonition-title">Nominal Data</p>
<p>It is important to remember that nominal data with more than two categories needs to be dummy-coded for the results to make sense (i.e., 0 or 1 coding). NeuroMiner does not recognize the types of a variable and therefore nominal data that is coded with more than three categories (e.g., 1=Depression; 2=Bipolar; 3=Schizophrenia) will be modeled as a variable with meaningful relationships between the numbers when differences are actually arbitrary.</p>
</div>
</div>
<div class="section" id="select-features-for-imputation">
<h3>2 | Select features for imputation<a class="headerlink" href="#select-features-for-imputation" title="Permalink to this heading">#</a></h3>
<p>The imputation procedures can be applied to the entire dataset or to subsets of the data. This is useful when there are different data domains (e.g., clinical and cognitive data) or even single questionnaires (e.g., the PANSS) that you want to restrict the imputation to. A MATLAB logical vector (i.e., consisting of TRUE and FALSE fields that are depicted as [0 0 0 1 1 0 0 etc.]; you can convert a binary vector to a logical simply by typing logical(yourvector) on the command line) must be provided to select a subset. If you want to impute multiple subsets then you must add separate imputation routines. Please note: If previous preprocessing operations change the dimensionality of the feature space (e.g. <a class="reference internal" href="#preproc-pruning"><span class="std std-ref">pruning</span></a>) these changes are propagated to the user-provided logical feature indices used by the imputation module.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If previous preprocessing operations change the dimensionality of the feature space (e.g. <a class="reference internal" href="#preproc-pruning"><span class="std std-ref">pruning</span></a>) these changes are propagated to the user-provided logical feature indices used by the imputation module.</p>
</div>
</div>
<div class="section" id="define-number-of-nearest-neighbors">
<h3>3 | Define number of nearest-neighbors<a class="headerlink" href="#define-number-of-nearest-neighbors" title="Permalink to this heading">#</a></h3>
<p>If you’re using the multivariate nearest-neighbors approach then you
must define the number of nearest neighbors (e.g., subjects) to use for
the calculation of the median value. The default is 7.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We found that this step yields stable results when data is scaled prior to the imputation step, however the results become unstable when the data is standardized.</p>
</div>
<hr class="docutils" />
</div>
</div>
<div class="section" id="prune-non-informative-columns-from-data-matrix">
<span id="preproc-pruning"></span><h2>Prune non-informative columns from data matrix<a class="headerlink" href="#prune-non-informative-columns-from-data-matrix" title="Permalink to this heading">#</a></h2>
<p>Data pruning is the removal of examples or features that will not work with machine learning algorithms or are redundant. In NeuroMiner, the machine learning algorithms that are used cannot work with missing values (i.e., ”Not a Number” (NaN) entries in MATLAB) or with infinite values (i.e., ”Inf” in MATLAB), which can occur due to previous processing steps. If the values of a feature do not change between participants (i.e., there is zero variance), then it is redundant to include the feature in the analysis as well. To correct for these problems, NeuroMiner offers the following options:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-prune">
<img alt="neurominer preprocessing pruning" src="_images/NM_preproc_prune.png" />
</div>
<p><strong>1 | Prune zero features [ no ]</strong></p>
<blockquote>
<div><p>The first option gives the user the ability to remove variables with no variance within a fold (i.e., if all individuals, or ’examples’ within a cross-validation fold have exactly the same value for a feature).</p>
</div></blockquote>
<p><strong>2 | Prune features with NaNs [ yes ]</strong></p>
<blockquote>
<div><p>The second option will remove features within a fold that have any NaN (’Not a Number’) values.</p>
</div></blockquote>
<p><strong>3 | Prune features with Infs [ yes ]</strong></p>
<blockquote>
<div><p>Similarly, the third option will allow users to remove features with any Infs (Infinity) values.</p>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>Be careful with pruning!</strong> Even if there is one subject with one NaN or Inf within the fold NeuroMiner will remove the feature. The amount of removed features will be difficult to quantify. For matrix data, check the NaNs and potentially filter them prior to the entry into NeuroMiner (see <a class="reference internal" href="4.1_mainmenu_input_data.html#fig-3-1-nm-feature-selector"><span class="std std-numref">Fig. 4</span></a>).</p>
</div>
<p><strong>4 | Prune features with single-value percentage over cutoff [ yes, 5 ]</strong></p>
<blockquote>
<div><p>The fourth option is used in situations where there are a large number of subjects with the same value and a few with different values. For example, in neuroimaging due to registration inaccuracies most of the subjects may have a voxel value of zero in a location close to the gray matter border and a few might have non-zero numbers. In these circumstances, you might want to exclude the voxels where there is no variance in, for example, 90% of the sample (e.g., where 90% of individuals have a zero value). You can specify a percentage here to do this.</p>
</div></blockquote>
</div>
<hr class="docutils" />
<div class="section" id="remove-group-level-differences-using-offset-correction">
<h2>Remove group-level differences using offset correction<a class="headerlink" href="#remove-group-level-differences-using-offset-correction" title="Permalink to this heading">#</a></h2>
<p>This function was introduced primarily to control for scanner differences in structural neuroimaging data. In the case of two centers, for each feature, the mean of both center A and center B is calculated. The mean difference between these is then calculated (A-B=Y) and then subtracted from each of the data points in A (i.e., Ai - Y). This value is stored for further analysis. Internal empirical tests indicate that this simple method can effectively control for major site differences.</p>
<hr class="docutils" />
</div>
<div class="section" id="rank-weight-features">
<span id="preproc-rank-weight"></span><h2>Rank / Weight features<a class="headerlink" href="#rank-weight-features" title="Permalink to this heading">#</a></h2>
<p>Selecting or ranking features is an important part of machine learning and can be achieved with filters and wrappers. For a discussion of why these methods are important and for all definitions see <a class="reference external" href="http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf">Guyon et
al., 2003</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Wrappers and will further be discussed in <a class="reference internal" href="4.2.05_paramtemp_ensemble_generation_strategies.html#ensemble-generation-strategies"><span class="std std-ref">ensemble generation straqtegies</span></a>.</p>
</div>
<p>Filter methods broadly involve the weighting and ranking of variables, and optionally the selection of top performing variables. This can be conducted either prior to the evaluation of the model during pre-processing or as part of model optimisation (discussed in section <a class="reference internal" href="4.2.05_paramtemp_ensemble_generation_strategies.html#ensemble-generation-strategies"><span class="std std-ref">ensemble generation straqtegies</span></a>). This option allows the user to weight variables in the training folds based on some criteria (e.g., Pearson’s correlation coefficient with the target variable) and then rank them in a specified order (e.g., descending order from most to least correlated). When this option is selected, the following will be displayed:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-rank">
<img alt="neurominer preprocessing ranking" src="_images/NM_preproc_rank.png" />
</div>
<p><strong>1 | Choose algorithm and specify its parameters</strong></p>
<p>The user here has the option to choose from among a number of methods
that will weight the relationship between the filter target and the
feature. These are:</p>
<div class="figure align-default" id="fig-3-2-02-nm-preproc-rank-method">
<img alt="neurominer preprocessing pruning" src="_images/NM_preproc_rank_method.png" />
</div>
<ol class="arabic simple">
<li><p><strong>Pearson / Spearman correlation</strong>:
Standard MATLAB functions for Pearson’s (corrcoef.m).</p></li>
<li><p><strong>Spearman correlation</strong>:
Standard MATLAB function for Spearman’s (corr.m).</p></li>
<li><p>G-flip (Greedy Feature Flip):
See <a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/Papers/giladbachrachnavottishby04b.pdf">Gilad-Bachrach et al.
(2004)</a>
and
<a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/code/feature_selection.bak/">site</a></p></li>
<li><p>Simba:
See <a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/Papers/giladbachrachnavottishby04b.pdf">Gilad-Bachrach et al.
(2004)</a>
and
<a class="reference external" href="http://www.cs.huji.ac.il/labs/learning/code/feature_selection.bak/">link</a></p></li>
<li><p>IMRelief:
This is an implementation of the Yijun Sun IMRelief function called
“IMRelief Sigmoid FastImplentation” (see <a class="reference external" href="http://plaza.ufl.edu/sunyijun/Paper/ICML06_1.pdf">Sun &amp; Li,
2007</a>).</p></li>
<li><p>Relief for classification:
This is a version of the built-in MATLAB ReliefF algorithm
<a class="reference external" href="https://de.mathworks.com/help/stats/relieff.html">(link</a>).</p></li>
<li><p>Linear SVC (LIBSVM):
This weights the features by conducting a linear SVM using each
independent feature, as implemented in LIBSVM <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">(Chang &amp;
Lin</a>).</p></li>
<li><p>Linear SVC (LIBLINEAR):
Weights the features based on using LIBLINEAR toolbox
(<a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">link</a>)</p></li>
<li><p>F-Score:
Weights the features based on conducting an ANOVA using standard MATLAB
functions on the differences between the groups when problem is
classification.</p></li>
<li><p>AUC:
Calculates an area under the curve (AUC) for binary classifications
based on the code of Chih-Jen Lin (<a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/papers/causality.pdf">Lin, 2008</a>)and then ranks the features based on
this.</p></li>
<li><p>FEAST:
Implementation of the FEAST toolbox for feature selection
(<a class="reference external" href="http://www.cs.man.ac.uk/~gbrown/fstoolbox/">site</a>).</p></li>
<li><p>ANOVA:
Standard implementation of ANOVA.</p></li>
<li><p>PLS:
Performs a Partial Least Squares analysis to rank the features.</p></li>
<li><p>External ranking:
This option uses a user-defined weighting template that was entered
during [data input] (input_data), to use an external weighting map
from a file, or to read-in a weighting vector using the MATLAB
workspace.</p></li>
</ol>
<p><strong>2 | Define target labels</strong>
Here the user defines the target label that the filter will be applied to using the original data; e.g., this could be your group labels if you have a classification problem or your questionnaire item if you’re using regression. The default setting in NeuroMiner is to use your target variable, but this can be changed by first selecting the menu item and then entering ”D” to define a new target label. A new menu will appear and you can select to enter either categorical or continuous data. You can then enter a MATLAB vector that defines either categorical labels (e.g., [0 0 0 0 1 1 1 1]) or continuous labels (e.g., [15 26 19 33 22]). These variables should be stored in your MATLAB workspace. When a continuous variable is selected, the user will then be asked whether they want to weight feature using only one specific subgroup. This means that the feature will only be weighted only based on the relationship between the feature and the filter target in one subgroup (e.g., control participants).</p>
<p><strong>3 | Up- or down-weight predictive features</strong>
This option allows the user to either upweight or downweight the features based on the relationship between the variable and the target. For example, if you want to increase the importance of the features based on the target you would upweight the features. If you want to reduce the importance of the fea tures based on some other variable (e.g., age if it is a nuisance variable) you could select the variable as the feature selection target and then choose the downweight option. For more information about why you would want to do this see references above.</p>
</div>
<hr class="docutils" />
<div class="section" id="extract-variance-components-from-data">
<h2>Extract variance components from data<a class="headerlink" href="#extract-variance-components-from-data" title="Permalink to this heading">#</a></h2>
<p>This function takes a source matrix and performs a PCA. It then determines correlations between the eigenvariates from the PCA reduction, and those above or below a specified threshold are identified. It then projects the target matrix to the source matrix PCA space, and then back-reconstructs this to the original input space without the identified PCA components (i.e., it removes the variance associated with those components).</p>
</div>
<hr class="docutils" />
<div class="section" id="measure-deviation-from-normative-data">
<h2>Measure deviation from normative data<a class="headerlink" href="#measure-deviation-from-normative-data" title="Permalink to this heading">#</a></h2>
<p>This function calculates a partial least squares (PLS) model and then determines how much the data deviates from the model that is produced. The hypothesis here is that the PLS model represents a normative variation between the primary features (i.e., your (processed by previous preprocessing steps in your pipeline) features which were entered into NM, e.g., brain data) and the second feature matrix which you can load into NM when setting up this step (e.g., covariates, like age and/or sex).</p>
<p><strong>How does it work?</strong>
PLS first extracts a set of latent factors that explain as much of the covariance as possible between the primary features and the covariate matrix. Next, a regression predicts values of the primary features using the decomposition of the covariates.</p>
<p>Finally, the normative deviation is computed (primary features - predicted primary feautures) and replaces the primary features in further processing steps.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The outcome label should <strong>not</strong> be entered in the covariate matrix since the information will otherwise be introduced into the processed feature data and, therefore, inflate performance.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="regression-mode-target-scaling-transformation">
<h2>Regression mode: Target scaling &amp; transformation<a class="headerlink" href="#regression-mode-target-scaling-transformation" title="Permalink to this heading">#</a></h2>
<p>In the regression setting, one has the option to enable scaling of the outcome variable (default). Further, a number of transformations for the outcome variable are available as well.</p>
</div>
<hr class="docutils" />
<div class="section" id="multiclass-mode-one-vs-one-one-vs-all-modus">
<h2>Multiclass mode: One vs. One, One vs. All Modus<a class="headerlink" href="#multiclass-mode-one-vs-one-one-vs-all-modus" title="Permalink to this heading">#</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="4.2.01_paramtemp_cv_settings.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Cross-validation settings</p>
      </div>
    </a>
    <a class="right-next"
       href="4.2.03_paramtemp_classification_algorithm.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classification algorithm</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#add-preprocessing-step">Add preprocessing step</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enable-spatial-operations-using-spatial-op-wizard">Enable spatial operations using Spatial OP Wizard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regress-out-nuisance-covariates">Regress out nuisance covariates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-correlations-options">Partial Correlations options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combat-options">ComBat options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#disparate-impact-remover-options">Disparate Impact Remover options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-dimensionality-reduction-method-to-data">Apply dimensionality reduction method to data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-subspaces">Extracting Subspaces</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-data">Standardize data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scale-data">Scale data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalize-to-group-mean">Normalize to group mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalize-to-unit-vector">Normalize to unit vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-binning-method-to-data">Apply binning method to data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#impute-missing-values">Impute missing values</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-imputation-method">1 | Define imputation method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-for-imputation">2 | Select features for imputation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-number-of-nearest-neighbors">3 | Define number of nearest-neighbors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prune-non-informative-columns-from-data-matrix">Prune non-informative columns from data matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remove-group-level-differences-using-offset-correction">Remove group-level differences using offset correction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-weight-features">Rank / Weight features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extract-variance-components-from-data">Extract variance components from data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measure-deviation-from-normative-data">Measure deviation from normative data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-mode-target-scaling-transformation">Regression mode: Target scaling &amp; transformation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiclass-mode-one-vs-one-one-vs-all-modus">Multiclass mode: One vs. One, One vs. All Modus</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://www.lmu-klinikum.de/psychiatrie-und-psychotherapie/forschung-research/working-groups/precision-psychiatry/7ef67d79b4ad4804">Section for Precision Psychiatry, Ludwig-Maximilian-University Munich</a> / <a href="https://www.psych.mpg.de/2571270/precision-psychiatry">Precision Psychiatry Group, Max Planck Institute of Psychiatry</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>